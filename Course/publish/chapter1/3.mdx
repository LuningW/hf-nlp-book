# Transformers 能做什么？[[Transformers 能做什么？]]

<CourseFloatingBanner chapter={1}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/zh-CN/chapter1/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/zh-CN/chapter1/section3.ipynb"},
]} />

在本节中，您将学习到 Transformer 模型可以做什么，并使用 🤗 Transformers 库中的第一个工具：pipeline() 函数。

## Transformers 无处不在！[[Transformer 被应用于各个方面！]]

Transformer 模型用于解决各种 NLP 任务，就像上一节提到的那样。以下是一些使用 Hugging Face 和 Transformer 模型的公司和组织，他们也分享他们的模型来回馈社区：

![使用 Hugging Face 的公司](https://huggingface.co/course/static/chapter1/companies.PNG)
 [🤗 Transformers 库](https://github.com/huggingface/transformers) 提供了创建和使用这些共享模型的功能。 [模型中心（hub）](https://huggingface.co/models) 包含数千个任何人都可以下载和使用的预训练模型。您还可以将自己的模型上传到 Hub！

<Tip>
⚠️ Hugging Face Hub 不只限于 Transformer 模型。每个人都可以分享任何类型的模型或数据。创建一个 [Huggingface.co 帐户](https://huggingface.co/join) 即可使用所有可用的功能。
</Tip>

在深入研究 Transformer 模型的底层工作原理之前，让我们先看几个示例，学习它们如何解决一些有趣的 NLP 问题。

## 使用 pipelines [[使用 pipelines]]

🤗 Transformers 库中最基本的对象是 **pipeline()** 函数。它将模型与所需的预处理和后处理步骤连接起来，使我们能够直接输入文本并获得结果：

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```

我们也可以多传几句！

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

默认情况下， pipeline 选择一个特定的预训练模型，该模型已针对基于英语的情感分析进行了微调。创建**classifier**对象的时候下载和缓存模型。如果您重新运行该命令，直接使用缓存的模型，无需再次加载模型。

将一些文本传递到 pipeline 的三个主要步骤：

1. 文本被预处理为模型可以理解的格式；
2. 将预处理过的数据作为输入传递给模型；
3. 对模型的预测结果进行后续处理并输出最终我们可以理解的结果。

目前 [可用的pipeline](https://huggingface.co/transformers/main_classes/pipelines.html) 有：

* **eature-extraction**（获取文本的向量表示）
* **fill-mask**(完形填空)
* **ner**（命名实体识别）
* **question-answering**(问答)
* **sentiment-analysis**(情感分析)
* **summarization**(提取摘要)
* **text-generation**(文本生成)
* **translation**(翻译)
* **zero-shot-classification**(零样本分类)

让我们来看看一些例子吧！

## 零样本分类 [[零样本分类]]

我们将从一个更具挑战性的任务开始——对没有标签的文本进行分类。这是实际项目中的常见场景，给文本打标签很耗时并且普遍需要对应领域内的专业知识。对于这项任务**zero-shot-classification**pipeline 非常强大：您可以直接指定用于分类的标签而不必依赖预训练模型的标签。下面的模型展示了如何使用 `教育` 、 `政治` 、或者 `商业`这三个标签将句子进行分类。当然您也可以使用喜欢的其他标签集对文本进行分类。

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```python
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

此pipeline 称为**zero-shot**(零次学习)，即不需要对数据上的模型进行任何微调就可以直接使用。它可以返回您想要的任何标签列表的概率值！
`<Tip>`
✏️**快来试试吧！**使用您自己的序列和标签，看看模型的表现如何。
`</Tip>`

## 文本生成 [[文本生成]]

让我们尝试一下另一个管道，这次是用于生成文本的 text-generation。这里的主要使用方法是您提供一个提示，模型将通过生成剩余的文本来自动完成整段话。这类似于许多手机上的预测文本功能。文本生成涉及随机性，因此如果您没有得到相同的如下所示的结果，这是正常的。

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python
[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows — data flows of various types, as seen by the '
                    'HTTP'}]
```

您可以使用参数 **num_return_sequences** 控制生成多少个不同的候选的句子，并使用参数 **max_length** 控制输出文本的总长度。

<Tip>
✏️**快来试试吧！**使用 num_return_sequences 和 max_length 参数生成两个句子，每个句子 15 个单词。
</Tip>

## 在 pipeline 中使用 Hub 中的其他模型 [[在 pipeline 中使用 Hub 中的其他模型]]

前面的示例使用了默认模型，您也可以从 Hub 中选择一个特定模型用于特定任务，例如文本生成。转到 [模型中心（hub）](https://huggingface.co/models) 并单击左侧的相应标签将会显示该任务支持的模型。您会看到一个 [这个页面](https://huggingface.co/models?pipeline_tag=text-generation) 的页面。

让我们试试 [**distilgpt2**](https://huggingface.co/distilgpt2) 模型吧！下面是在之前的 pipeline 中加载它的方法：

```python
from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```

```python
[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]
```

您可以单击语言标签来筛选搜索结果，然后选择另一种文本生成的模型。模型中心（Hub）包含支持多语言的模型。单击选择模型后您会看到一个小组件，可以直接在线下载并使用测试模型的功能。
`<Tip>`
✏️**快来试试吧！**使用标签筛选查找另一种语言的文本生成模型，使用小组件并在 pipeline 中测试它！
`</Tip>`

## 推理 API [[推理 API]]

所有模型都可以使用 Inference API 直接通过浏览器进行测试，该 API 可在 [Hugging Face 网站](https://huggingface.co/) 上找到。您可以在此页面上使用该模型，输入自定义文本并观察模型的输出。

## 完形填空 [[Mask filling]]

下一个 pipeline 是 **fill-mask**。这个任务用来填补给定文本中的空白：

```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

```python
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

**top_k** 该参数控制要显示多少种结果。注意这里的模型填补了特殊的 `<mask>` 词，通常被称为*掩码标记*。不同的掩码填充模型有不同的掩码标记，因此您在探索其他模型时不要忘记验证正确的掩码字是什么。这里提供一种检查方法：您可以查看小组件中使用的掩码标记。

<Tip>
✏️**快来试试吧！**在 Hub 上搜索 `bert-base-cased` 模型并在推理 API 小组件中找到它的掩码标记。对于上面 pipeline 示例中的句子，这个模型预测了什么？
</Tip>

## 命名实体识别 [[命名实体识别]]

命名实体识别 (NER) 任务为模型必须找到输入文本的哪些部分对应于诸如人员、位置或组织之类已经被命名的实体。让我们看一个示例：

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

这里模型正确地识别出 Sylvain 是一个人 (PER)，Hugging Face 是一个组织 (ORG)，而布鲁克林是一个位置 (LOC)。

我们在创建 pipeline 的函数中传递选项 **grouped_entities=True** ，告诉 pipeline 要把同一实体对应的句子内容重新分组：比如在上面的示例中模型正确地将“Hugging”和“Face”分组为一个组织，即使这个名称由多个词组成。我们即将在下一章学习到，预处理会将一些单词分成更小的部分。例如，**Sylvain** 分割为了四部分：**S、##yl、##va** 和 **##in**。而在后处理中pipeline 又重新把这些分割的部分组合起来。

<Tip>
✏️**快来试试吧！**在模型中心（hub）搜索能够用英语进行词性标注（通常缩写为 POS）的模型。对于上面示例中的句子，这个模型预测了什么？
</Tip>

## 问答 [[问答系统]]

 `question-answering` pipeline 使用给定上下文中的信息回答问题：

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
klyn",
)

```

注意 pipeline 只能通过提供的上下文提取信息来工作，它不会凭空生成答案。

## 提取摘要 [[文本摘要]]

提取摘要是将文本缩减为较短文本的任务，同时尽可能保留文本中的主要信息。下面是一个示例：

```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
"""
)
```

```python
[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]
```

与文本生成一样，由您来指定结果的 **max_length** 或 **min_length**。

## 翻译 [[翻译]]

对于翻译任务 ，如果您在任务的名称中包含语言对（例如“**translation_en_to_fr**”），可以使用默认模型，但最简单的方法是在 [模型中心（hub）](https://huggingface.co/models) 选择要使用的模型。下面的示例中为尝试把法语翻译成英语：

```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python
[{'translation_text': 'This course is produced by Hugging Face.'}]

```

与文本生成和提取摘要任务一样，您可以指定结果的 **max_length** 或 **min_length**。

<Tip>

✏️**快来试试吧！**搜索其他语言的翻译模型，尝试将前面的句子翻译成几种不同的语言。

</Tip>

目前为止显示的 pipeline 主要用于示例演示，它们是为特定任务而编程。在下一章中您将了解 **pipeline()** 函数内部的具体过程以及如何进行自定义修改。
