### 1. 探索 Hub 并寻找 `roberta-large-mnli` checkpoint。 它可以完成什么类型的任务？


1. 文本摘要提取
2. 文本分类
3. 文本生成

### 2. 下面的代码将会输出什么结果？

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```
1. 它将输出带有 \"positive\" 或者 \"negative\"标签分类的分数。
2. 它将生成这句话的下一句话。
3. 它找出代表人员、组织或位置的单词。

### 3. 在此代码示例中...的地方应该填写什么？

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```
1. This <mask> has been waiting for you.
2. This [MASK] has been waiting for you.
3. This man has been waiting for you.

### 4. 为什么这段代码会无法运行？

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```
1. 这个pipeline要求提供用来分类此文本的标签。
2. 这个pipeline需要多个句子，而不仅仅是一个。
3. 🤗 Transformers库又出故障了
4. 该pipeline需要更长的输入； 这个句子太短了。

### 5. “迁移学习”是什么意思？


1. 通过在同一数据集上再次训练模型，将预训练模型的知识迁移到新模型。
2. 通过使用第一个模型的权重初始化第二个模型，将预训练模型的知识迁移到新模型。
3. 构建与第一个模型具有相同架构的第二个模型，将预训练模型的知识迁移到新模型。

### 6. 语言模型在预训练时通常不需要标签，这样的说法是否正确。


1. 正确
2. 错误

### 7. 选择最能描述“模型(model)”、“架构(architecture)”和“权重(weights)”的句子。


1. 如果模型是一座建筑物，那么它的架构就是蓝图，而权重就是住在里面的人。
2. 架构是建立模型的地图，权重是地图上表示的城市。
3. 架构是用于构建模型的一系列数学函数，其权重是这些函数参数。

### 8. 你将使用以下哪种类型的模型来根据输入的提示生成文本？


1. “编码器”模型
2. “解码器”模型
3. “序列到序列”模型

### 9. 你会使用哪些类型的模型来生成文本的摘要？


1. “编码器”模型
2. “解码器”模型
3. “序列到序列”模型

### 10. 你会使用哪一种类型的模型来根据特定的标签对文本输入进行分类？


1. “编码器”模型
2. “解码器”模型
3. “序列到序列”模型

### 11. 模型中观察到的偏见有哪些可能的来源？


1. 这个模型是一个预训练模型的微调版本，它从中继承了预训练模型的偏见。
2. 用于训练模型的数据是有偏见的。
3. 模型优化的指标是有偏见的。

---

### 1. 探索 Hub 并寻找 `roberta-large-mnli` checkpoint。 它可以完成什么类型的任务？


正确选项: 2. 文本分类

1. 文本摘要提取    
解析: 请前往 [roberta-large-mnli 页面](https://huggingface.co/roberta-large-mnli) 再仔细看一下.
2. 文本分类    
解析: 更准确地说，它能判断两句话是否在逻辑上有关联，通过三个标签（矛盾，无关，蕴含）分类——这项任务也称为<em>自然语言推理</em>.
3. 文本生成    
解析: 请前往 [roberta-large-mnli 页面](https://huggingface.co/roberta-large-mnli) 回顾一下.

### 2. 下面的代码将会输出什么结果？

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```
正确选项: 3. 它找出代表人员、组织或位置的单词。

1. 它将输出带有 \"positive\" 或者 \"negative\"标签分类的分数。    
解析: 错误 — <code>sentiment-analysis（情感分析）</code> pipeline才会输出这些。
2. 它将生成这句话的下一句话。    
解析: 错误— <code>text-generation（文本生成）</code> pipeline才会输出这些。
3. 它找出代表人员、组织或位置的单词。    
解析: 正解! 此外，使用 <code>grouped_entities=True</code>，可以将属于同一实体的单词组合在一起，例如“Hugging Face”。

### 3. 在此代码示例中...的地方应该填写什么？

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```
正确选项: 2. This [MASK] has been waiting for you.

1. This <mask> has been waiting for you.    
解析: 错误。请查看 <code>bert-base-cased</code> 模型卡片
2. This [MASK] has been waiting for you.    
解析: 正解! 这个模型的掩码标记是[MASK].
3. This man has been waiting for you.    
解析: 错误。 这个pipeline的作用是填充经过mask的文字，因此它需要在输入中有一个掩码标记。

### 4. 为什么这段代码会无法运行？

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```
正确选项: 1. 这个pipeline要求提供用来分类此文本的标签。

1. 这个pipeline要求提供用来分类此文本的标签。    
解析: 正解 — 正确的代码需要包含：<code>candidate_labels=[...]</code>.
2. 这个pipeline需要多个句子，而不仅仅是一个。    
解析: 错误。尽管正确使用时，此pipeline可以同时处理多个句子（像所有其他pipeline一样）。
3. 🤗 Transformers库又出故障了    
解析: 对此，我们不予置评！
4. 该pipeline需要更长的输入； 这个句子太短了。    
解析: 错误。 不过请注意，在这个pipeline处理太长的文本时会将其截断。

### 5. “迁移学习”是什么意思？


正确选项: 2. 通过使用第一个模型的权重初始化第二个模型，将预训练模型的知识迁移到新模型。

1. 通过在同一数据集上再次训练模型，将预训练模型的知识迁移到新模型。    
解析: 不，那将是同一模型的两个版本。
2. 通过使用第一个模型的权重初始化第二个模型，将预训练模型的知识迁移到新模型。    
解析: 正确：当第二个模型接受新任务训练时，它*迁移*第一个模型的知识。
3. 构建与第一个模型具有相同架构的第二个模型，将预训练模型的知识迁移到新模型。    
解析: 架构只是模型的构建方式； 在这种情况下，没有知识共享或迁移。

### 6. 语言模型在预训练时通常不需要标签，这样的说法是否正确。


正确选项: 1. 正确

1. 正确    
解析: 预训练通常是<em>自监督</em>，这意味着标签是根据输入自动创建的（例如：预测下一个单词或填充一些[MARSK]单词）。
2. 错误    
解析: 这不是一个正确的答案。

### 7. 选择最能描述“模型(model)”、“架构(architecture)”和“权重(weights)”的句子。


正确选项: 3. 架构是用于构建模型的一系列数学函数，其权重是这些函数参数。

1. 如果模型是一座建筑物，那么它的架构就是蓝图，而权重就是住在里面的人。    
解析: 按照这个比喻，更准确地来说权重应该是用于建造建筑物的砖块和其他材料。
2. 架构是建立模型的地图，权重是地图上表示的城市。    
解析: 这个比喻的问题在于，一张地图通常代表只有一个确定的事实（法国只有一个城市叫巴黎）。 对于给定的体系结构，可能有多个权重。
3. 架构是用于构建模型的一系列数学函数，其权重是这些函数参数。    
解析: 同一组数学函数（架构）可以通过使用不同的参数（权重）来构建不同的模型。

### 8. 你将使用以下哪种类型的模型来根据输入的提示生成文本？


正确选项: 2. “解码器”模型

1. “编码器”模型    
解析: “编码器”模型生成整个句子的表示，这种表示更适合于分类之类的任务。
2. “解码器”模型    
解析: “解码器”模型非常适合根据提示生成文本。
3. “序列到序列”模型    
解析: “序列到序列”模型更适合于根据输入句子生成句子的任务而不是给定提示。

### 9. 你会使用哪些类型的模型来生成文本的摘要？


正确选项: 3. “序列到序列”模型

1. “编码器”模型    
解析: “编码器”模型生成整个句子的表示，这种表示更适合于分类这样的任务。
2. “解码器”模型    
解析: “解码器”模型对于生成输出文本(如摘要)很好，但它们不具备利用上下文(如整个文本)进行总结的能力。
3. “序列到序列”模型    
解析: “序列到序列”模型非常适合摘要任务。

### 10. 你会使用哪一种类型的模型来根据特定的标签对文本输入进行分类？


正确选项: 1. “编码器”模型

1. “编码器”模型    
解析: “编码器”模型可以生成整个句子的表示，非常适合分类这样的任务。
2. “解码器”模型    
解析: “解码器”模型适合于生成输出文本，而不是从句子中提取标签。
3. “序列到序列”模型    
解析: “序列到序列”模型更适合于输入句子而不是标签生成文本的任务。

### 11. 模型中观察到的偏见有哪些可能的来源？


正确选项: 1. 这个模型是一个预训练模型的微调版本，它从中继承了预训练模型的偏见。

正确选项: 2. 用于训练模型的数据是有偏见的。

正确选项: 3. 模型优化的指标是有偏见的。

1. 这个模型是一个预训练模型的微调版本，它从中继承了预训练模型的偏见。    
解析: 当应用迁移学习时，在预训练模型中产生的偏见在微调模型中不能完全去除。
2. 用于训练模型的数据是有偏见的。    
解析: 这是最明显的偏见来源，但不是唯一的来源。
3. 模型优化的指标是有偏见的。    
解析: 一个不太明显的偏见来源是模型的训练方式。 你的模型将盲目地只针对你选择的指标进行优化，而不会思考这样是否会带有偏见。

